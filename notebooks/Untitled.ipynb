{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jun 13 2020 \n",
      "\n",
      "CPython 3.8.3\n",
      "IPython 7.13.0\n",
      "\n",
      "numpy 1.18.1\n",
      "scipy not installed\n",
      "sklearn not installed\n",
      "pandas 1.0.3\n",
      "\n",
      "compiler   : Clang 10.0.0 \n",
      "system     : Darwin\n",
      "release    : 19.4.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -n -m -p numpy,scipy,sklearn,pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "PROJ_ROOT = os.path.abspath(os.path.join(os.pardir))\n",
    "sys.path.append(os.path.join(PROJ_ROOT, \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from models.decision_tree import DecisionTree\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(os.path.join(PROJ_ROOT, \"data\",\"processed\",\"validate_data.xlsx\"),index_col =0)\n",
    "header = df1.columns.values.tolist()\n",
    "labels = df1[[\"G3\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49824720117607135"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [13, 11, 12, 11, 13, 12, 10, 10, 12, 11, 16, 13, 9, 11, 12, 12, 13, 13, 12, 11, 13, 13, 11, 10, 11, 10, 10, 11, 12, 14, 13, 12, 13, 13, 12, 11, 13, 13, 13, 14, 10, 14, 14, 12, 14, 13, 17, 13, 10, 11, 13, 11, 16, 10, 12, 10, 11, 11, 13, 13, 10, 13, 13, 11, 13, 13, 16, 13, 13, 14, 12, 12, 11, 13, 12, 12, 10, 12, 10, 13, 10, 10, 11, 13, 11, 12, 10, 13, 13, 13, 13, 11, 10, 14, 10, 10, 11, 13, 10, 11, 13, 13, 12, 13, 14, 13, 16, 16, 13, 12, 15, 13, 12, 13, 10, 10, 10, 12, 14, 11, 13, 10, 11, 13, 11, 13, 10, 10, 13]\n",
    "TSS = np.sum((np.array(labels) - np.array(labels).mean())** 2)\n",
    "ESS = np.sum((np.array(predictions) - np.array(labels).mean()) ** 2)\n",
    "\n",
    "ESS/TSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2a8debb27a09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclass_counts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_numeric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgini\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgini_impurity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munique_vals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_tree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDecisionTree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLeaf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQuestion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/random_forest/RandomForest/src/models/decision_tree.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclass_counts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_numeric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgini\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgini_impurity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munique_vals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from models.utils import class_counts,is_numeric,partition,gini,gini_impurity,unique_vals\n",
    "from models.decision_tree import DecisionTree,DecisionTree,Leaf,Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "    \n",
    "class DecisionNode(DecisionTree):\n",
    "    \"\"\"A Decision Node asks a question.\n",
    "\n",
    "    This holds a reference to the question, and to the two child nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 question,\n",
    "                 true_branch,\n",
    "                 false_branch):\n",
    "        \n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "GINI_IMPURITY = \"gini\"\n",
    "INFO_GAIN = 'info_gain'\n",
    "\n",
    "class DecisionTree: \n",
    "    \n",
    "    def __init__(self,\n",
    "                 question=None,\n",
    "                 true_branch=None,\n",
    "                 false_branch=None,\n",
    "                 metrics=None, \n",
    "                 max_depth=None,\n",
    "                 leafs=None,\n",
    "                 final_leaf=None):\n",
    "        \n",
    "        self.question = question\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "        self.max_depth = max_depth\n",
    "        self.final_leaf = final_leaf\n",
    "        \n",
    "        if metrics is None:\n",
    "            self.metrics = GINI_IMPURITY     \n",
    "   \n",
    "        if leafs is None:\n",
    "            self.leafs = []      \n",
    "        \n",
    "    def build_tree(self,train_data,header,count=0):\n",
    "        \n",
    "        \"\"\"Builds the tree.\n",
    "    \n",
    "        Rules of recursion: 1) Believe that it works. 2) Start by checking\n",
    "        for the base case (no further information gain). 3) Prepare for\n",
    "        giant stack traces.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Try partitioing the dataset on each of the unique attribute,\n",
    "        # calculate the information gain,\n",
    "        # and return the question that produces the highest gain.\n",
    "        \n",
    "        #print(\"nÂ° features: {}\".format(len(train_data[0]) - 1))\n",
    "        gain, question = self.find_best_split(train_data,header)\n",
    "        #print(\"--input data: {}\".format(train_data))\n",
    "        logger.info(\"--best question is ''{}'' with information gain: {}\".format(question,round(gain,2)))\n",
    "        # Base case: no further info gain\n",
    "        # Since we can ask no further questions,\n",
    "        # we'll return a leaf.\n",
    "        \n",
    "        print(\"--\",count)\n",
    "        print(\"--\",gain)\n",
    "        \n",
    "        if isinstance(train_data,pd.DataFrame):\n",
    "            train_data = train_data.values.tolist()\n",
    "            \n",
    "        if gain < 0.001:\n",
    "            print(\"final_gain=\",gain)\n",
    "            \n",
    "            leafs = self.leafs.append(Leaf(train_data))\n",
    "            print(leafs)\n",
    "            return DecisionTree(None,\n",
    "                                self.true_branch, \n",
    "                                self.false_branch,\n",
    "                                self.metrics,\n",
    "                                self.max_depth,\n",
    "                                leafs,\n",
    "                                Leaf(train_data))\n",
    "        \n",
    "        if count == self.max_depth:\n",
    "            print(\"final_depth=\",count)\n",
    "            self.leafs.append(Leaf(train_data))\n",
    "            \n",
    "            return DecisionTree(None,\n",
    "                                self.true_branch, \n",
    "                                self.false_branch,\n",
    "                                self.metrics,\n",
    "                                self.max_depth,\n",
    "                                self.leafs,\n",
    "                                Leaf(train_data))\n",
    "    \n",
    "        true_rows, false_rows = partition(train_data, question)\n",
    "        \n",
    "        # Recursively build the true branch.\n",
    "        logger.info(\"\\n----TRUE BRANCH----\")\n",
    "        true_branch = self.build_tree(true_rows,header,count+1)\n",
    "        \n",
    "        # Recursively build the false branch.\n",
    "        logger.info(\"\\n----FALSE BRANCH----\")\n",
    "        false_branch = self.build_tree(false_rows,header,count+1)\n",
    "        \n",
    "        return DecisionTree(question,\n",
    "                            true_branch, \n",
    "                            false_branch,\n",
    "                            self.metrics,\n",
    "                            self.max_depth,\n",
    "                            self.leafs,\n",
    "                            None)\n",
    "    \n",
    "    \n",
    "    def initialize_split(self,train_data):\n",
    "        \n",
    "        if self.metrics == GINI_IMPURITY:\n",
    "            # Calculate the information gain from this split\n",
    "            current_uncertainty = gini(train_data)\n",
    "               \n",
    "        if self.metrics == INFO_GAIN:\n",
    "            # TODO:\n",
    "            pass\n",
    "        \n",
    "        return current_uncertainty\n",
    "        \n",
    "    def find_best_split(self,train_data,header):\n",
    "        \"\"\"Find the best question to ask by iterating over every feature / value\n",
    "        and calculating the information gain.\"\"\"\n",
    "    \n",
    "        if isinstance(train_data,pd.DataFrame):\n",
    "            train_data = train_data.values.tolist()\n",
    "        \n",
    "        N_FEATURES = len(train_data[0]) - 1  # number of columns\n",
    "        \n",
    "        best_gain = 0  # keep track of the best information gain\n",
    "        best_question = None  # keep train of the feature / value that produced it\n",
    "        current_uncertainty = self.initialize_split(train_data)\n",
    "        \n",
    "        for col in range(N_FEATURES):  # for each feature\n",
    "            \n",
    "            values = unique_vals(train_data, col)  # unique values in the column\n",
    "            logger.info(\"values features nÂ° {} ''{}'': {}\".format(col+1,header[col],values))\n",
    "            for val in values:  # for each value\n",
    "        \n",
    "                question = Question(header,col, val)\n",
    "                \n",
    "                # try splitting the dataset\n",
    "                true_rows, false_rows = partition(train_data, question)\n",
    "                \n",
    "                # Skip this split if it doesn't divide the dataset.\n",
    "                if len(true_rows) == 1 or len(false_rows) == 1:\n",
    "                    \n",
    "                    continue\n",
    "                \n",
    "                if self.metrics == GINI_IMPURITY:\n",
    "                    # Calculate the information gain from this split\n",
    "                    gain = gini_impurity(true_rows, false_rows, current_uncertainty)\n",
    "               \n",
    "                if self.metrics == INFO_GAIN:\n",
    "                    # TODO:\n",
    "                    pass\n",
    "               \n",
    "                if gain >= best_gain:\n",
    "                    best_gain, best_question = gain, question\n",
    "    \n",
    "        return best_gain, best_question\n",
    "\n",
    "\n",
    "    def classify(self,row):\n",
    "        \"\"\"See the 'rules of recursion' above.\"\"\"\n",
    "        \n",
    "        # Base case: we've reached a leaf\n",
    "        if self.true_branch == None or self.true_branch == None:\n",
    "            logger.info(\"predictions: {} \".format(self.final_leaf.predictions))\n",
    "            return self.final_leaf.predictions\n",
    "    \n",
    "        print(\"tree_classifier->classify:\",self.question)\n",
    "        \n",
    "        #print(\"input value {}\".format(row[node.question.column]))\n",
    "        \n",
    "        #print(self.question.match(row))\n",
    "        if self.question.match(row):\n",
    "            print(\"yes\",self)\n",
    "            return self.true_branch.classify(row)\n",
    "        else:\n",
    "            print(\"no\",self)\n",
    "            return self.false_branch.classify(row)\n",
    "    \n",
    "\n",
    "    def __repr__(self, spacing=\"\"):\n",
    "        \"\"\"World's most elegant tree printing function.\"\"\"\n",
    "    \n",
    "        # Base case: we've reached a leaf\n",
    "        if self.true_branch == None or self.true_branch == None:\n",
    "            print (spacing + \"Predict\", str(print_leaf(self.final_leaf.predictions)))\n",
    "            return \"--- END ---\"\n",
    "        \n",
    "        # Print the question at this node\n",
    "        print (spacing + str(self.question))\n",
    "    \n",
    "        # Call this function recursively on the true branch\n",
    "        print (spacing + '--> True:')\n",
    "        self.true_branch.__repr__(spacing + \"  \")\n",
    "    \n",
    "        # Call this function recursively on the false branch\n",
    "        print (spacing + '--> False:')\n",
    "        self.false_branch.__repr__(spacing + \"  \")\n",
    "        \n",
    "        return \"--- END ---\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_leaf(counts):\n",
    "    \"\"\"A nicer way to print the predictions at a leaf.\"\"\"\n",
    "    total = sum(counts.values()) * 1.0\n",
    "    probs = {}\n",
    "    for lbl in counts.keys():\n",
    "        probs[lbl] = str(int(counts[lbl] / total * 100)) + \"%\"\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{17: '100%'}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {17: 3}\n",
    "print_leaf(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 0\n",
      "-- 0.11716158855152903\n",
      "-- 1\n",
      "-- 0.1152524254401725\n",
      "-- 2\n",
      "-- 0.20132325141776936\n",
      "-- 3\n",
      "-- 0.2666666666666667\n",
      "-- 4\n",
      "-- 0.48\n",
      "-- 5\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 5\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 4\n",
      "-- 0.4444444444444445\n",
      "-- 5\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 5\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 3\n",
      "-- 0.22500000000000003\n",
      "-- 4\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 4\n",
      "-- 0.07999999999999993\n",
      "-- 5\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 5\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 2\n",
      "-- 0.10243803879310343\n",
      "-- 3\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 3\n",
      "-- 0.08866637461668436\n",
      "-- 4\n",
      "-- 0.1866666666666665\n",
      "-- 5\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 5\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 4\n",
      "-- 0.08801309493830281\n",
      "-- 5\n",
      "-- 0.2203856749311295\n",
      "-- 6\n",
      "-- 0.1111111111111111\n",
      "-- 7\n",
      "-- 0.5\n",
      "-- 8\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 8\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 7\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 6\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 5\n",
      "-- 0.31250000000000006\n",
      "-- 6\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 6\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 1\n",
      "-- 0.09510459280442024\n",
      "-- 2\n",
      "-- 0.04644322027753445\n",
      "-- 3\n",
      "-- 0.08377025385823028\n",
      "-- 4\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 4\n",
      "-- 0.04013676230117441\n",
      "-- 5\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 5\n",
      "-- 0.028702709153836964\n",
      "-- 6\n",
      "-- 0.0295475530932596\n",
      "-- 7\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 7\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 6\n",
      "-- 0.09382716049382722\n",
      "-- 7\n",
      "-- 0.11999999999999983\n",
      "-- 8\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 8\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 7\n",
      "-- 0.5\n",
      "-- 8\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 8\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 3\n",
      "-- 0.13860544217687076\n",
      "-- 4\n",
      "-- 0.21875\n",
      "-- 5\n",
      "-- 0.375\n",
      "-- 6\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 6\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 5\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 4\n",
      "-- 0.36111111111111116\n",
      "-- 5\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 5\n",
      "-- 0.125\n",
      "-- 6\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 6\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 2\n",
      "-- 0.17839102719277022\n",
      "-- 3\n",
      "-- 0.1654245408570667\n",
      "-- 4\n",
      "-- 0.23883808499193107\n",
      "-- 5\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 5\n",
      "-- 0.07438016528925631\n",
      "-- 6\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 6\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 4\n",
      "-- 0.375\n",
      "-- 5\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 5\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 3\n",
      "-- 0.10857142857142854\n",
      "-- 4\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 4\n",
      "-- 0.1020408163265307\n",
      "-- 5\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n",
      "-- 5\n",
      "-- 0.0\n",
      "final_gain= 0.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dt = dt.build_tree(df1,df1.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is freetime >= 4?\n",
      "--> True:\n",
      "  Predict {17: '100%'}\n",
      "--> False:\n",
      "  Predict {18: '100%'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "--- END ---"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.true_branch.true_branch.true_branch.true_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DecisionTree' object has no attribute 'leafs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-112e264a825c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleafs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DecisionTree' object has no attribute 'leafs'"
     ]
    }
   ],
   "source": [
    "dt.leafs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_classifier->classify: Is G2 >= 12?\n",
      "yes Is G2 >= 12?\n",
      "--> True:\n",
      "  Is G2 >= 14?\n",
      "  --> True:\n",
      "    Is G2 >= 15?\n",
      "    --> True:\n",
      "      Is G2 >= 17?\n",
      "      --> True:\n",
      "        Is freetime >= 4?\n",
      "        --> True:\n",
      "          Predict {17: '100%'}\n",
      "        --> False:\n",
      "          Predict {18: '100%'}\n",
      "      --> False:\n",
      "        Is activities == no?\n",
      "        --> True:\n",
      "          Predict {16: '100%'}\n",
      "        --> False:\n",
      "          Predict {15: '100%'}\n",
      "    --> False:\n",
      "      Is Fjob == at_home?\n",
      "      --> True:\n",
      "        Predict {15: '100%'}\n",
      "      --> False:\n",
      "        Is traveltime >= 2?\n",
      "        --> True:\n",
      "          Predict {15: '50%', 14: '50%'}\n",
      "        --> False:\n",
      "          Predict {14: '100%'}\n",
      "  --> False:\n",
      "    Is absences >= 12?\n",
      "    --> True:\n",
      "      Predict {14: '100%'}\n",
      "    --> False:\n",
      "      Is Fjob == services?\n",
      "      --> True:\n",
      "        Is traveltime >= 3?\n",
      "        --> True:\n",
      "          Predict {14: '66%', 13: '33%'}\n",
      "        --> False:\n",
      "          Predict {13: '100%'}\n",
      "      --> False:\n",
      "        Is Medu >= 3?\n",
      "        --> True:\n",
      "          Is Medu >= 4?\n",
      "          --> True:\n",
      "            Is G1 >= 12?\n",
      "            --> True:\n",
      "              Is goout >= 3?\n",
      "              --> True:\n",
      "                Predict {12: '100%'}\n",
      "              --> False:\n",
      "                Predict {13: '100%'}\n",
      "            --> False:\n",
      "              Predict {12: '100%'}\n",
      "          --> False:\n",
      "            Predict {13: '100%'}\n",
      "        --> False:\n",
      "          Is age >= 18?\n",
      "          --> True:\n",
      "            Predict {13: '33%', 9: '33%', 14: '33%'}\n",
      "          --> False:\n",
      "            Predict {12: '100%'}\n",
      "--> False:\n",
      "  Is G2 >= 10?\n",
      "  --> True:\n",
      "    Is absences >= 1?\n",
      "    --> True:\n",
      "      Is Fjob == health?\n",
      "      --> True:\n",
      "        Predict {10: '100%'}\n",
      "      --> False:\n",
      "        Is Dalc >= 5?\n",
      "        --> True:\n",
      "          Predict {10: '33%', 9: '33%', 11: '33%'}\n",
      "        --> False:\n",
      "          Is famsize == GT3?\n",
      "          --> True:\n",
      "            Is higher == no?\n",
      "            --> True:\n",
      "              Predict {11: '66%', 10: '33%'}\n",
      "            --> False:\n",
      "              Predict {11: '100%'}\n",
      "          --> False:\n",
      "            Is guardian == mother?\n",
      "            --> True:\n",
      "              Is absences >= 4?\n",
      "              --> True:\n",
      "                Predict {11: '100%'}\n",
      "              --> False:\n",
      "                Predict {10: '50%', 11: '50%'}\n",
      "            --> False:\n",
      "              Is freetime >= 3?\n",
      "              --> True:\n",
      "                Predict {12: '100%'}\n",
      "              --> False:\n",
      "                Predict {11: '100%'}\n",
      "    --> False:\n",
      "      Is Fedu >= 2?\n",
      "      --> True:\n",
      "        Is studytime >= 2?\n",
      "        --> True:\n",
      "          Is internet == yes?\n",
      "          --> True:\n",
      "            Predict {11: '100%'}\n",
      "          --> False:\n",
      "            Predict {10: '50%', 12: '50%'}\n",
      "        --> False:\n",
      "          Predict {10: '100%'}\n",
      "      --> False:\n",
      "        Is school == MS?\n",
      "        --> True:\n",
      "          Predict {9: '100%'}\n",
      "        --> False:\n",
      "          Is G2 >= 11?\n",
      "          --> True:\n",
      "            Predict {11: '50%', 12: '50%'}\n",
      "          --> False:\n",
      "            Predict {11: '100%'}\n",
      "  --> False:\n",
      "    Is age >= 17?\n",
      "    --> True:\n",
      "      Is G2 >= 9?\n",
      "      --> True:\n",
      "        Is Medu >= 4?\n",
      "        --> True:\n",
      "          Predict {11: '100%'}\n",
      "        --> False:\n",
      "          Is goout >= 2?\n",
      "          --> True:\n",
      "            Predict {10: '100%'}\n",
      "          --> False:\n",
      "            Predict {10: '50%', 9: '50%'}\n",
      "      --> False:\n",
      "        Is guardian == mother?\n",
      "        --> True:\n",
      "          Predict {7: '50%', 8: '50%'}\n",
      "        --> False:\n",
      "          Predict {9: '100%'}\n",
      "    --> False:\n",
      "      Is famsup == no?\n",
      "      --> True:\n",
      "        Predict {8: '33%', 9: '33%', 7: '33%'}\n",
      "      --> False:\n",
      "        Is absences >= 8?\n",
      "        --> True:\n",
      "          Predict {11: '50%', 8: '50%'}\n",
      "        --> False:\n",
      "          Predict {8: '100%'}\n",
      "--- END ---\n",
      "tree_classifier->classify: Is G2 >= 14?\n",
      "yes Is G2 >= 14?\n",
      "--> True:\n",
      "  Is G2 >= 15?\n",
      "  --> True:\n",
      "    Is G2 >= 17?\n",
      "    --> True:\n",
      "      Is freetime >= 4?\n",
      "      --> True:\n",
      "        Predict {17: '100%'}\n",
      "      --> False:\n",
      "        Predict {18: '100%'}\n",
      "    --> False:\n",
      "      Is activities == no?\n",
      "      --> True:\n",
      "        Predict {16: '100%'}\n",
      "      --> False:\n",
      "        Predict {15: '100%'}\n",
      "  --> False:\n",
      "    Is Fjob == at_home?\n",
      "    --> True:\n",
      "      Predict {15: '100%'}\n",
      "    --> False:\n",
      "      Is traveltime >= 2?\n",
      "      --> True:\n",
      "        Predict {15: '50%', 14: '50%'}\n",
      "      --> False:\n",
      "        Predict {14: '100%'}\n",
      "--> False:\n",
      "  Is absences >= 12?\n",
      "  --> True:\n",
      "    Predict {14: '100%'}\n",
      "  --> False:\n",
      "    Is Fjob == services?\n",
      "    --> True:\n",
      "      Is traveltime >= 3?\n",
      "      --> True:\n",
      "        Predict {14: '66%', 13: '33%'}\n",
      "      --> False:\n",
      "        Predict {13: '100%'}\n",
      "    --> False:\n",
      "      Is Medu >= 3?\n",
      "      --> True:\n",
      "        Is Medu >= 4?\n",
      "        --> True:\n",
      "          Is G1 >= 12?\n",
      "          --> True:\n",
      "            Is goout >= 3?\n",
      "            --> True:\n",
      "              Predict {12: '100%'}\n",
      "            --> False:\n",
      "              Predict {13: '100%'}\n",
      "          --> False:\n",
      "            Predict {12: '100%'}\n",
      "        --> False:\n",
      "          Predict {13: '100%'}\n",
      "      --> False:\n",
      "        Is age >= 18?\n",
      "        --> True:\n",
      "          Predict {13: '33%', 9: '33%', 14: '33%'}\n",
      "        --> False:\n",
      "          Predict {12: '100%'}\n",
      "--- END ---\n",
      "tree_classifier->classify: Is G2 >= 15?\n",
      "no Is G2 >= 15?\n",
      "--> True:\n",
      "  Is G2 >= 17?\n",
      "  --> True:\n",
      "    Is freetime >= 4?\n",
      "    --> True:\n",
      "      Predict {17: '100%'}\n",
      "    --> False:\n",
      "      Predict {18: '100%'}\n",
      "  --> False:\n",
      "    Is activities == no?\n",
      "    --> True:\n",
      "      Predict {16: '100%'}\n",
      "    --> False:\n",
      "      Predict {15: '100%'}\n",
      "--> False:\n",
      "  Is Fjob == at_home?\n",
      "  --> True:\n",
      "    Predict {15: '100%'}\n",
      "  --> False:\n",
      "    Is traveltime >= 2?\n",
      "    --> True:\n",
      "      Predict {15: '50%', 14: '50%'}\n",
      "    --> False:\n",
      "      Predict {14: '100%'}\n",
      "--- END ---\n",
      "tree_classifier->classify: Is Fjob == at_home?\n",
      "no Is Fjob == at_home?\n",
      "--> True:\n",
      "  Predict {15: '100%'}\n",
      "--> False:\n",
      "  Is traveltime >= 2?\n",
      "  --> True:\n",
      "    Predict {15: '50%', 14: '50%'}\n",
      "  --> False:\n",
      "    Predict {14: '100%'}\n",
      "--- END ---\n",
      "tree_classifier->classify: Is traveltime >= 2?\n",
      "no Is traveltime >= 2?\n",
      "--> True:\n",
      "  Predict {15: '50%', 14: '50%'}\n",
      "--> False:\n",
      "  Predict {14: '100%'}\n",
      "--- END ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{14: 8}"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.classify(df1.values.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    ['Green', 3, 'Apple'],\n",
    "    ['Yellow', 3, 'Apple'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Yellow', 3, 'Lemon'],\n",
    "    ['Green', 3, 'Apple'],\n",
    "    ['Yellow', 4, 'Apple'],\n",
    "    ['Red', 2, 'Grape'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Yellow', 3, 'Lemon']\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
